{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['datetime', 'test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for calculating accurate distances betwen lat/long points\n",
    "#from geopy.distance import vincenty\n",
    "\n",
    "from calendar import monthrange\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "#from itertools import chain\n",
    "\n",
    "from astral import Astral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import given data\n",
    "date_parser = lambda x: datetime.strptime(x, \"%Y-%m-%d\")\n",
    "\n",
    "train = pd.read_csv('../input/train.csv', parse_dates=['Date'], date_parser=date_parser)[['Date', 'Address', 'Species', 'Block', 'Street', 'Trap', 'AddressNumberAndStreet', 'Latitude', 'Longitude', 'AddressAccuracy', 'NumMosquitos', 'WnvPresent']]\n",
    "test = pd.read_csv('../input/test.csv',  parse_dates=['Date'], date_parser=date_parser)[['Id', 'Date', 'Address', 'Species', 'Block', 'Street', 'Trap', 'AddressNumberAndStreet', 'Latitude', 'Longitude', 'AddressAccuracy']]\n",
    "\n",
    "weather = pd.read_csv('../input/weather.csv', index_col=1, parse_dates=['Date'], date_parser=date_parser)[['Station', 'Tmax', 'Tmin', 'Tavg', 'Depart', 'DewPoint', 'WetBulb', 'Heat', 'Cool', 'Depth', 'Water1', 'SnowFall', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import usgs data\n",
    "usgs_04087440 = pd.read_table('../input/usgs_04087440.txt', comment='#', index_col=2, parse_dates=['datetime'], date_parser=date_parser)[['01_00065_00003']]\n",
    "usgs_05536105 = pd.read_table('../input/usgs_05536105.txt', comment='#', index_col=2, parse_dates=['datetime'], date_parser=date_parser)[['01_00065_00003']]\n",
    "usgs_05536118 = pd.read_table('../input/usgs_05536118.txt', comment='#', index_col=2, parse_dates=['datetime'], date_parser=date_parser)[['01_00065_00003']]\n",
    "usgs_05536121 = pd.read_table('../input/usgs_05536121.txt', comment='#', index_col=2, parse_dates=['datetime'], date_parser=date_parser)[['02_00065_00003']]\n",
    "usgs_05536123 = pd.read_table('../input/usgs_05536123.txt', comment='#', index_col=2, parse_dates=['datetime'], date_parser=date_parser)[['35_00065_00003']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# weather processing\n",
    "#weather_codes = np.unique(list(chain(*weather.CodeSum.str.split().tolist())))\n",
    "\n",
    "# replace letters, combine stations\n",
    "weather.replace('[a-zA-Z]', 0, regex=True, inplace=True)\n",
    "weather_merged = pd.merge(weather[weather.Station == 1], weather[weather.Station == 2], left_index=True, right_index=True, suffixes=['_1', '_2'])\n",
    "weather_merged.drop(weather_merged.filter(regex='Station').columns, axis=1, inplace=True)\n",
    "\n",
    "# add merged weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# usgs processing\n",
    "usgs_df = pd.DataFrame(index=weather_merged.index, columns=['USGS04087440', 'USGS05536105', 'USGS05536118', 'USGS05536121', 'USGS05536123'])\n",
    "usgs_df['USGS04087440'] = usgs_04087440['01_00065_00003']\n",
    "usgs_df['USGS05536105'] = usgs_05536105['01_00065_00003']\n",
    "usgs_df['USGS05536118'] = usgs_05536118['01_00065_00003']\n",
    "usgs_df['USGS05536121'] = usgs_05536121['02_00065_00003']\n",
    "usgs_df['USGS05536123'] = usgs_05536123['35_00065_00003']\n",
    "usgs_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# astral\n",
    "city_name = 'Chicago'\n",
    "a = Astral()\n",
    "a.solar_depression = 'civil'\n",
    "city = a[city_name]\n",
    "\n",
    "#astral_df = pd.DataFrame(index=weather_merged.index, columns=['MoonPhase', 'Dawn', 'Sunrise', 'Noon', 'Sunset', 'Dusk'])\n",
    "astral_df = pd.DataFrame(index=weather_merged.index, columns=['MoonPhase', 'Sunrise', 'Sunset',])\n",
    "for date in astral_df.index:\n",
    "    sun = city.sun(date=date, local=True)\n",
    "    #dawn = (sun['dawn'] - city.tz.localize(date)).total_seconds()/3600.0\n",
    "    sunrise = (sun['sunrise'] - city.tz.localize(date)).total_seconds()/3600.0\n",
    "    #noon = (sun['noon'] - city.tz.localize(date)).total_seconds()/3600.0\n",
    "    sunset = (sun['sunset'] - city.tz.localize(date)).total_seconds()/3600.0\n",
    "    #dusk = (sun['dusk'] - city.tz.localize(date)).total_seconds()/3600.0\n",
    "    #astral_df.ix[date] = [city.moon_phase(date=date), dawn, sunrise, noon, sunset, dusk]\n",
    "    astral_df.ix[date] = [city.moon_phase(date=date), sunrise, sunset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# species\n",
    "#species = pd.get_dummies(train.Species)\n",
    "#train[species.columns] = species\n",
    "#train.drop('Species', axis=1, inplace=True)\n",
    "\n",
    "species_lb = LabelBinarizer()\n",
    "species_lb.fit(list(train['Species'].values) + list(test['Species'].values))\n",
    "species_list = species_lb.classes_.tolist()\n",
    "#print species_lb.transform(train['Species'].values)\n",
    "\n",
    "#species_le = LabelEncoder()\n",
    "#species_le.fit(list(train['Species'].values) + list(test['Species'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode trap values\n",
    "#trap_le = LabelEncoder()\n",
    "#trap_le.fit(list(train['Trap'].values) + list(test['Trap'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for generating features\n",
    "def gen_features(data):\n",
    "    # start with empty dataframe\n",
    "    x = pd.DataFrame(index=data.index)\n",
    "    \n",
    "    # add date\n",
    "    x['Date'] = data['Date']\n",
    "    x['DayOfWeek'] = data.Date.apply(lambda x: x.weekday())\n",
    "    x['DayOfMonth'] = data.Date.apply(lambda x: x.day)\n",
    "    x['DayOfYear'] = data.Date.apply(lambda x: x.timetuple().tm_yday)\n",
    "    \n",
    "    # add location\n",
    "    #x[['Latitude', 'Longitude']] = data[['Latitude', 'Longitude']]\n",
    "    #x['AddressAccuracy'] = data['AddressAccuracy']\n",
    "    #x['Trap'] = trap_le.transform(data['Trap'].values)\n",
    "    \n",
    "    # add species\n",
    "    x[species_list] = pd.DataFrame(species_lb.transform(data['Species'].values), index=data.index, columns=species_list)\n",
    "    #x['Species'] = species_le.transform(data['Species'].values)\n",
    "    \n",
    "    # merge astral\n",
    "    x_merged = pd.merge(x, astral_df, left_on='Date', right_index=True)\n",
    "    \n",
    "    # merge usgs\n",
    "    x_merged = pd.merge(x_merged, usgs_df, left_on='Date', right_index=True)\n",
    "    \n",
    "    # merge weather\n",
    "    x_merged = pd.merge(x_merged, weather_merged, left_on='Date', right_index=True)\n",
    "    x_merged.drop('Date', axis=1, inplace=True)\n",
    "    \n",
    "    return x_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get train and test data\n",
    "X_train = gen_features(train)\n",
    "X_train['WnvPresent'] = train['WnvPresent']\n",
    "X_test = gen_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output to csv\n",
    "X_train.to_csv('../working/train_f.csv')\n",
    "X_test.to_csv('../working/test_f.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
