{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for calculating accurate distances betwen lat/long points\n",
    "#from geopy.distance import vincenty\n",
    "\n",
    "from calendar import monthrange\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "#from itertools import chain\n",
    "\n",
    "#from astral import Astral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import given data\n",
    "date_parser = lambda x: datetime.strptime(x, \"%Y-%m-%d\")\n",
    "\n",
    "train = pd.read_csv('../input/train.csv', dtype=str, parse_dates=['Date'], date_parser=date_parser)[['Date', 'Address', 'Species', 'Block', 'Street', 'Trap', 'AddressNumberAndStreet', 'Latitude', 'Longitude', 'AddressAccuracy', 'NumMosquitos', 'WnvPresent']]\n",
    "test = pd.read_csv('../input/test.csv', dtype=str, parse_dates=['Date'], date_parser=date_parser)[['Id', 'Date', 'Address', 'Species', 'Block', 'Street', 'Trap', 'AddressNumberAndStreet', 'Latitude', 'Longitude', 'AddressAccuracy']]\n",
    "\n",
    "weather = pd.read_csv('../input/weather.csv', index_col=1, parse_dates=['Date'], date_parser=date_parser)[['Station', 'Tmax', 'Tmin', 'Tavg', 'DewPoint', 'WetBulb', 'Cool', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed']]\n",
    "\n",
    "#elevation = pd.read_csv('../input/elevation.csv', dtype=str, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# import usgs data\n",
    "usgs_04087440 = pd.read_table('../input/usgs_04087440.txt', comment='#', index_col=2, parse_dates=['datetime'], date_parser=date_parser)[['01_00065_00003']]\n",
    "usgs_05536105 = pd.read_table('../input/usgs_05536105.txt', comment='#', index_col=2, parse_dates=['datetime'], date_parser=date_parser)[['01_00065_00003']]\n",
    "usgs_05536118 = pd.read_table('../input/usgs_05536118.txt', comment='#', index_col=2, parse_dates=['datetime'], date_parser=date_parser)[['01_00065_00003']]\n",
    "usgs_05536121 = pd.read_table('../input/usgs_05536121.txt', comment='#', index_col=2, parse_dates=['datetime'], date_parser=date_parser)[['02_00065_00003']]\n",
    "usgs_05536123 = pd.read_table('../input/usgs_05536123.txt', comment='#', index_col=2, parse_dates=['datetime'], date_parser=date_parser)[['35_00065_00003']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# weather processing\n",
    "#weather_codes = np.unique(list(chain(*weather.CodeSum.str.split().tolist())))\n",
    "\n",
    "# replace letters, combine stations\n",
    "weather.replace('[a-zA-Z]', 0, regex=True, inplace=True)\n",
    "weather_merged = pd.merge(weather[weather.Station == 1], weather[weather.Station == 2], left_index=True, right_index=True, suffixes=['_1', '_2'])\n",
    "weather_merged.drop(weather_merged.filter(regex='Station').columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create weather data\n",
    "weather_data = pd.DataFrame(index=weather_merged.index)\n",
    "\n",
    "# add weather for previous days\n",
    "days = range(5)\n",
    "for i in days:\n",
    "    weather_data = pd.merge(weather_data, weather_merged.shift(i), left_index=True, right_index=True, suffixes=['', '_d' + str(i)])\n",
    "    \n",
    "# add weather moving averages\n",
    "avg = [3, 7, 14, 21]\n",
    "weather_avg = pd.DataFrame(index=weather_merged.index)\n",
    "for i in avg:\n",
    "    weather_data = pd.merge(weather_data, pd.rolling_mean(weather_merged, i), left_index=True, right_index=True, suffixes=['', '_a' + str(i)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# usgs processing\n",
    "usgs_df = pd.DataFrame(index=weather_merged.index, columns=['USGS04087440', 'USGS05536105', 'USGS05536118', 'USGS05536121', 'USGS05536123'])\n",
    "usgs_df['USGS04087440'] = usgs_04087440['01_00065_00003']\n",
    "usgs_df['USGS05536105'] = usgs_05536105['01_00065_00003']\n",
    "usgs_df['USGS05536118'] = usgs_05536118['01_00065_00003']\n",
    "usgs_df['USGS05536121'] = usgs_05536121['02_00065_00003']\n",
    "usgs_df['USGS05536123'] = usgs_05536123['35_00065_00003']\n",
    "usgs_df.fillna(0, inplace=True)\n",
    "\n",
    "# add usgs data by days\n",
    "days = range(21)\n",
    "usgs_days = pd.DataFrame(index=weather_merged.index)\n",
    "for i in days:\n",
    "    usgs_days = pd.merge(usgs_days, usgs_df.shift(i), left_index=True, right_index=True, suffixes=['', '_d' + str(i)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# astral\n",
    "city_name = 'Chicago'\n",
    "a = Astral()\n",
    "a.solar_depression = 'civil'\n",
    "city = a[city_name]\n",
    "\n",
    "#astral_df = pd.DataFrame(index=weather_merged.index, columns=['MoonPhase', 'Dawn', 'Sunrise', 'Noon', 'Sunset', 'Dusk'])\n",
    "astral_df = pd.DataFrame(index=weather_merged.index, columns=['MoonPhase', 'Sunrise', 'Sunset'])\n",
    "for date in astral_df.index:\n",
    "    sun = city.sun(date=date, local=True)\n",
    "    #dawn = (sun['dawn'] - city.tz.localize(date)).total_seconds()/3600.0\n",
    "    sunrise = (sun['sunrise'] - city.tz.localize(date)).total_seconds()/3600.0\n",
    "    #noon = (sun['noon'] - city.tz.localize(date)).total_seconds()/3600.0\n",
    "    sunset = (sun['sunset'] - city.tz.localize(date)).total_seconds()/3600.0\n",
    "    #dusk = (sun['dusk'] - city.tz.localize(date)).total_seconds()/3600.0\n",
    "    #astral_df.ix[date] = [city.moon_phase(date=date), dawn, sunrise, noon, sunset, dusk]\n",
    "    astral_df.ix[date] = [city.moon_phase(date=date), sunrise, sunset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# species\n",
    "#species = pd.get_dummies(train.Species)\n",
    "#train[species.columns] = species\n",
    "#train.drop('Species', axis=1, inplace=True)\n",
    "\n",
    "species_lb = LabelBinarizer()\n",
    "species_lb.fit(list(train['Species'].values) + list(test['Species'].values))\n",
    "species_list = species_lb.classes_.tolist()\n",
    "#print species_lb.transform(train['Species'].values)\n",
    "\n",
    "#species_le = LabelEncoder()\n",
    "#species_le.fit(list(train['Species'].values) + list(test['Species'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode trap values\n",
    "#trap_le = LabelEncoder()\n",
    "#trap_le.fit(list(train['Trap'].values) + list(test['Trap'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10506, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2007"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print train.shape\n",
    "train.iloc[0]['Date'].year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for generating features\n",
    "def gen_features(data):\n",
    "    # start with empty dataframe\n",
    "    x = pd.DataFrame(index=data.index)\n",
    "    \n",
    "    # add date\n",
    "    x['Date'] = data['Date']\n",
    "    #x['DayOfWeek'] = data.Date.apply(lambda x: x.weekday())\n",
    "    #x['DayOfMonth'] = data.Date.apply(lambda x: x.day)\n",
    "    #x['DayOfYear'] = data.Date.apply(lambda x: x.timetuple().tm_yday)\n",
    "    x['Week'] = data['Date'].apply(lambda d: d.isocalendar()[1])\n",
    "    x['Year'] = data['Date'].apply(lambda d: d.year)\n",
    "    \n",
    "    # add location\n",
    "    x[['Latitude', 'Longitude']] = data[['Latitude', 'Longitude']]\n",
    "    #x['AddressAccuracy'] = data['AddressAccuracy']\n",
    "    #x['Trap'] = trap_le.transform(data['Trap'].values)\n",
    "    \n",
    "    # add species\n",
    "    x[species_list] = pd.DataFrame(species_lb.transform(data['Species'].values), index=data.index, columns=species_list)\n",
    "    #x['Species'] = species_le.transform(data['Species'].values)\n",
    "    \n",
    "    # merge astral\n",
    "    #x_merged = pd.merge(x, astral_df, left_on='Date', right_index=True)\n",
    "    \n",
    "    # merge elevatoin\n",
    "    #x_merged = pd.merge(x_merged, elevation, how='left', left_on=['Latitude', 'Longitude'], right_on=['Latitude', 'Longitude'])\n",
    "    \n",
    "    # merge usgs\n",
    "    #x_merged = pd.merge(x_merged, usgs_days, left_on='Date', right_index=True)\n",
    "    \n",
    "    # merge weather\n",
    "    x = pd.merge(x, weather_data, left_on='Date', right_index=True)\n",
    "    \n",
    "    # drop date\n",
    "    x.drop('Date', axis=1, inplace=True)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get train and test data\n",
    "X_train = gen_features(train)\n",
    "X_train['NumMosquitos'] = train['NumMosquitos']\n",
    "X_train['WnvPresent'] = train['WnvPresent']\n",
    "X_test = gen_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-37ca4c1e7120>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mXd_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#print X_train['NumMosquitos'].astype(int).sum()/X_train['NumMosquitos'].count()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NumMosquitos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "Xd_train = gen_data(X_train, 10)\n",
    "#print X_train['NumMosquitos'].astype(int).sum()/X_train['NumMosquitos'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output to csv\n",
    "X_train.to_csv('../working/train_f.csv')\n",
    "X_test.to_csv('../working/test_f.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
