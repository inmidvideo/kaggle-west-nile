{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import datetime, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load train and test data\n",
    "wnv_train = np.loadtxt('../working/train_f.csv', delimiter=',', dtype=float64, skiprows=1)\n",
    "wnv_test = np.loadtxt('../working/test_f.csv', delimiter=',', dtype=float64, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# raw data\n",
    "yr_train = wnv_train[:,1].astype(int)\n",
    "Xr_train = wnv_train[:,2:]\n",
    "Xr_test = wnv_test[:,1:]\n",
    "\n",
    "# normalize data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xr_train)\n",
    "Xn_train = scaler.transform(Xr_train)\n",
    "Xn_test = scaler.transform(Xr_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xn_train, yr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_neighbors = 3\n",
    "n_components = 65\n",
    "n_estimators = 1000\n",
    "n_jobs = 3\n",
    "p_level = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "clf = ExtraTreesClassifier(n_estimators=n_estimators, n_jobs=n_jobs)\n",
    "#clf.fit(X_train, y_train)\n",
    "clf.fit(Xn_train, yr_train)\n",
    "\n",
    "# use the model to predict the labels of the test data\n",
    "predicted = clf.predict(X_test)\n",
    "proba = clf.predict_proba(X_test)\n",
    "expected = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.980966882375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      2489\n",
      "          1       0.98      0.65      0.78       138\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2627\n",
      "\n",
      "[[2487    2]\n",
      " [  48   90]]\n",
      "0.994838157458\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "matches = (predicted == expected)\n",
    "print matches.sum() / float(len(matches))\n",
    "\n",
    "# f1 score\n",
    "from sklearn import metrics\n",
    "print metrics.classification_report(expected, predicted)\n",
    "\n",
    "# confusion matrix\n",
    "print metrics.confusion_matrix(expected, predicted)\n",
    "\n",
    "# auc\n",
    "print metrics.roc_auc_score(expected, proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "print np.count_nonzero(predicted == 1)\n",
    "print np.count_nonzero(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.607352380952\n"
     ]
    }
   ],
   "source": [
    "proba = clf.predict_proba(Xn_test)\n",
    "print np.max(proba[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "def write_preds(proba, fname):\n",
    "    pd.DataFrame({\"Id\": list(range(1,len(proba)+1)), \"WnvPresent\": proba}).to_csv(fname, index=False, header=True)\n",
    "\n",
    "#write_preds(preds[range(28000)], \"keras-mlp_\" + st + \".csv\")\n",
    "write_preds(proba[:,1], \"../working/sklearn_test_\" + st + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
